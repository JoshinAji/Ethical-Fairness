{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e230b91c-9c7d-4f7f-a04f-bf0f2ea2cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Subset size: 900  | FairFace: 539  | UTKFace: 361\n",
      "✅ data/splits/master.csv written.\n",
      "source_dataset\n",
      "FairFace    539\n",
      "UTKFace     361\n",
      "Name: count, dtype: int64\n",
      "race_cat\n",
      "White         342\n",
      "Black         301\n",
      "EastAsian     129\n",
      "SouthAsian    128\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c3/ll608w4j6fb5s23c0wwscp240000gn/T/ipykernel_16300/1291946638.py:14: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pool = pd.read_csv(\"../data/pool.csv\")\n"
     ]
    }
   ],
   "source": [
    "# build_subset_robust.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_TOTAL = 900\n",
    "FAIRFACE_RATIO = 0.60     # 60/40 split FairFace/UTKFace\n",
    "SEED = 42\n",
    "\n",
    "# Races you care about (adjust if needed)\n",
    "RACES = ['White','Black','EastAsian','SouthAsian','SoutheastAsian','MiddleEastern','Latino']\n",
    "\n",
    "# 1) Load pool\n",
    "pool = pd.read_csv(\"../data/pool.csv\")\n",
    "pool = pool[pool['race_cat'].isin(RACES)].copy()\n",
    "\n",
    "# Sanity: make a unique key for safety (image_id should be unique already)\n",
    "#assert pool['image_id'].is_unique, \"image_id not unique; check pool building.\"\n",
    "\n",
    "# 2) Decide per-source totals\n",
    "N_ff  = int(TARGET_TOTAL * FAIRFACE_RATIO)\n",
    "N_utk = TARGET_TOTAL - N_ff\n",
    "\n",
    "# 3) Decide per-race quotas\n",
    "#    Heuristic: equal quota per race overall, but races that only exist in FairFace\n",
    "#    (e.g., SoutheastAsian, MiddleEastern, Latino) are pulled entirely from FairFace.\n",
    "per_race_total = {r: TARGET_TOTAL // len(RACES) for r in RACES}\n",
    "remainder = TARGET_TOTAL - sum(per_race_total.values())\n",
    "# distribute the leftover  (makes totals exact)\n",
    "for r in RACES[:remainder]:\n",
    "    per_race_total[r] += 1\n",
    "\n",
    "# Which races are “FF-only” in practice? (UTK may have 0 count for some)\n",
    "counts_by_source = pool.groupby(['source_dataset','race_cat']).size().unstack(fill_value=0)\n",
    "ff_only = [r for r in RACES if counts_by_source.get(r, pd.Series()).get('UTKFace', 0) == 0]\n",
    "\n",
    "# 4) Split the per-race quota into per-source race quotas\n",
    "per_race_ff  = {}\n",
    "per_race_utk = {}\n",
    "for r in RACES:\n",
    "    t = per_race_total[r]\n",
    "    if r in ff_only:\n",
    "        per_race_ff[r]  = min(t, counts_by_source.get(r, pd.Series()).get('FairFace', 0))\n",
    "        per_race_utk[r] = 0\n",
    "    else:\n",
    "        # default: 60/40 split, but cap by availability\n",
    "        ff_avail  = counts_by_source.get(r, pd.Series()).get('FairFace', 0)\n",
    "        utk_avail = counts_by_source.get(r, pd.Series()).get('UTKFace', 0)\n",
    "        ff_q = min(int(round(t * FAIRFACE_RATIO)), ff_avail)\n",
    "        utk_q = min(t - ff_q, utk_avail)\n",
    "        # if UTK is too small, push remainder back to FairFace (if possible), and vice versa\n",
    "        if ff_q + utk_q < t:\n",
    "            deficit = t - (ff_q + utk_q)\n",
    "            # try filling from whichever has remaining availability\n",
    "            ff_room  = ff_avail  - ff_q\n",
    "            utk_room = utk_avail - utk_q\n",
    "            take_ff  = min(deficit, max(ff_room, 0))\n",
    "            ff_q    += take_ff\n",
    "            deficit -= take_ff\n",
    "            if deficit > 0:\n",
    "                utk_q += min(deficit, max(utk_room, 0))\n",
    "        per_race_ff[r], per_race_utk[r] = ff_q, utk_q\n",
    "\n",
    "# 5) Initial per-race sampling by source\n",
    "rng = np.random.RandomState(SEED)\n",
    "def sample_quota(df, n):\n",
    "    n = max(0, int(n))\n",
    "    if len(df) <= n:\n",
    "        return df.copy()\n",
    "    return df.sample(n=n, random_state=SEED)\n",
    "\n",
    "picked_ff  = []\n",
    "picked_utk = []\n",
    "for r in RACES:\n",
    "    df_ff  = pool[(pool.source_dataset=='FairFace') & (pool.race_cat==r)]\n",
    "    df_utk = pool[(pool.source_dataset=='UTKFace') & (pool.race_cat==r)]\n",
    "    picked_ff.append(sample_quota(df_ff,  per_race_ff[r]))\n",
    "    picked_utk.append(sample_quota(df_utk, per_race_utk[r]))\n",
    "\n",
    "subset = pd.concat(picked_ff + picked_utk, ignore_index=True).drop_duplicates('image_id')\n",
    "\n",
    "# 6) Top-up if we’re short overall or per-source\n",
    "def top_up(source_name, need, subset, pool, seed=42):\n",
    "    \"\"\"\n",
    "    Add up to `need` rows from `pool` for a given `source_name`,\n",
    "    excluding any image_id already in `subset`.\n",
    "    \"\"\"\n",
    "    if need <= 0:\n",
    "        return subset\n",
    "\n",
    "    # Ensure image_id is string (avoid dtype mismatches in isin)\n",
    "    pool = pool.copy()\n",
    "    subset = subset.copy()\n",
    "    pool['image_id'] = pool['image_id'].astype(str)\n",
    "    subset['image_id'] = subset['image_id'].astype(str)\n",
    "\n",
    "    # Anti-join by image_id\n",
    "    in_subset = set(subset['image_id'])\n",
    "    pool_src = pool[(pool['source_dataset'] == source_name) & (~pool['image_id'].isin(in_subset))]\n",
    "\n",
    "    take = min(int(need), len(pool_src))\n",
    "    if take > 0:\n",
    "        add = pool_src.sample(n=take, random_state=seed)\n",
    "        subset = pd.concat([subset, add], ignore_index=True).drop_duplicates('image_id')\n",
    "\n",
    "    return subset\n",
    "\n",
    "\n",
    "def count_source(df, name): return (df.source_dataset==name).sum()\n",
    "\n",
    "def finalize_subset_exact(subset, pool, target_total, seed=42):\n",
    "    \"\"\"\n",
    "    Ensure subset has exactly target_total rows.\n",
    "    1) If short, fill from ANY remaining pool rows (no race/source constraints).\n",
    "    2) If still short (pool exhausted), return best effort and warn.\n",
    "    3) If over, downsample to exact target.\n",
    "    \"\"\"\n",
    "    subset = subset.drop_duplicates('image_id').copy()\n",
    "    cur = len(subset)\n",
    "    if cur < target_total:\n",
    "        deficit = target_total - cur\n",
    "        # candidates = pool rows not already in subset\n",
    "        pool_ids = set(pool['image_id'].astype(str))\n",
    "        sub_ids  = set(subset['image_id'].astype(str))\n",
    "        remaining_ids = list(pool_ids - sub_ids)\n",
    "        if remaining_ids:\n",
    "            remaining = pool[pool['image_id'].astype(str).isin(remaining_ids)]\n",
    "            take = min(deficit, len(remaining))\n",
    "            add = remaining.sample(n=take, random_state=seed)\n",
    "            subset = pd.concat([subset, add], ignore_index=True).drop_duplicates('image_id')\n",
    "            cur = len(subset)\n",
    "            deficit = target_total - cur\n",
    "        if deficit > 0:\n",
    "            print(f\"⚠️ Pool exhausted for final fill; short by {deficit}. Returning best available = {cur}.\")\n",
    "            return subset  # cannot reach target; dataset limit\n",
    "\n",
    "    if len(subset) > target_total:\n",
    "        subset = subset.sample(n=target_total, random_state=seed)\n",
    "\n",
    "    return subset\n",
    "\n",
    "\n",
    "# Exact per-source targets\n",
    "need_ff  = N_ff  - count_source(subset, 'FairFace')\n",
    "need_utk = N_utk - count_source(subset, 'UTKFace')\n",
    "\n",
    "subset = top_up('FairFace', need_ff, subset, pool, seed=SEED)\n",
    "subset = top_up('UTKFace',  need_utk, subset, pool, seed=SEED)\n",
    "\n",
    "\n",
    "# If still short of overall TARGET_TOTAL (e.g., both sources exhausted some strata), fill from any remaining pool\n",
    "still_short = TARGET_TOTAL - len(subset)\n",
    "if still_short > 0:\n",
    "    remain = pool.drop(subset.index, errors='ignore')\n",
    "    fill = remain.sample(min(still_short, len(remain)), random_state=SEED)\n",
    "    subset = pd.concat([subset, fill], ignore_index=True).drop_duplicates('image_id')\n",
    "\n",
    "# Trim if we overshot due to rounding\n",
    "if len(subset) > TARGET_TOTAL:\n",
    "    subset = subset.sample(n=TARGET_TOTAL, random_state=SEED)\n",
    "\n",
    "# Final sanity\n",
    "# Force exact size using any remaining rows (no constraints)\n",
    "subset = finalize_subset_exact(subset, pool, TARGET_TOTAL, seed=SEED)\n",
    "\n",
    "ff_ct  = count_source(subset, 'FairFace')\n",
    "utk_ct = count_source(subset, 'UTKFace')\n",
    "\n",
    "if len(subset) != TARGET_TOTAL:\n",
    "    # We tried everything; pool simply doesn't have enough unique rows left.\n",
    "    print(f\"⚠️ Subset has {len(subset)} rows; target {TARGET_TOTAL}. \"\n",
    "          f\"This indicates pool exhaustion after filters/dedup.\")\n",
    "else:\n",
    "    print(f\"✅ Subset size: {len(subset)}  | FairFace: {ff_ct}  | UTKFace: {utk_ct}\")\n",
    "\n",
    "\n",
    "# 7) Train/val/test stratified split (by race)\n",
    "train, temp = train_test_split(subset, test_size=0.30, random_state=SEED, stratify=subset['race_cat'])\n",
    "val,   test = train_test_split(temp,   test_size=0.50, random_state=SEED, stratify=temp['race_cat'])\n",
    "\n",
    "def tag(df, name): df=df.copy(); df['split']=name; return df\n",
    "master = pd.concat([tag(train,'train'), tag(val,'val'), tag(test,'test')], ignore_index=True)\n",
    "\n",
    "# Save\n",
    "master.to_csv(\"../data/splits/master.csv\", index=False)\n",
    "print(\"✅ data/splits/master.csv written.\")\n",
    "print(master['source_dataset'].value_counts())\n",
    "print(master['race_cat'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
